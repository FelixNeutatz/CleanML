{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version specifies a random portion of missingness in the features. It is identical with missing_cleanml-2-percentage. These two notebooks are used to run datasets in parallel. Airbnb in particular takes a long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ds3lab-scratch/raox/gatech_data_cleaning/ICDE2021-revision/nacl36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/mnt/ds3lab-scratch/raox/gatech_data_cleaning/ICDE2021-revision/nacl36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import mlrose\n",
    "import utils\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import f1_score \n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pylab\n",
    "import sys\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "import keras\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../NaCL/code/\")\n",
    "import utils\n",
    "import LR2NB_GP\n",
    "sys.path.append(\"../NaCL/notebooks/\")\n",
    "from dataload import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ds3lab-scratch/raox/gatech_data_cleaning/ICDE2021-revision/nacl36/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from preprocess_mv import preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed = 3659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"data-robustml-mv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = \"result-robustml\"\n",
    "model_name ='nacl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = lambda x,y: np.mean(x == y)\n",
    "f1 = lambda x,y: f1_score(x,y.flatten(), average = \"weighted\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'Airbnb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs: 20\n"
     ]
    }
   ],
   "source": [
    "jobs = get_jobs_mv(data_dir, dataset = [dataset])\n",
    "print(\"Number of jobs:\", len(jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['data-robustml-mv', 'Airbnb', 'missing_values', 'split_8093'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_235'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_5396'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_5192'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_2962'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_7751'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_4764'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_2895'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_8444'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_6542'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_9394'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_4225'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_5374'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_3562'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_5056'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_3462'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_7813'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_144'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_2516'],\n",
       " ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_905']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = lambda x,y: np.mean(x == y)\n",
    "f1 = lambda x,y: f1_score(x,y.flatten(), average = \"weighted\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/mnt/ds3lab-scratch/raox/gatech_data_cleaning/ICDE2021-revision/CleanML/result/{}_result.json'.format(dataset)) as json_file:\n",
    "    results = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ['data-robustml-mv', 'Airbnb', 'missing_values', 'split_8093']\n",
      "--------------\n",
      "dataset: {'data_dir': 'Airbnb', 'error_types': ['duplicates', 'outliers', 'missing_values'], 'label': 'Rating', 'categorical_variables': ['Rating'], 'ml_task': 'classification', 'key_columns': ['latitude', 'longitude']}\n",
      "columns to encode: ['LocationName']\n",
      "(12, [12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Train Accuracy: 0.7034285714285714 \n",
      "LR Test  Accuracy: 0.6824444444444444\n",
      "Using solver 'cvxopt'\n",
      " for 954 free variables\n",
      "  in 956 posynomial inequalities.\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for job in jobs:\n",
    "    \n",
    "    \n",
    "    print(\"Processing\", job)\n",
    "    print('--------------')\n",
    "    dataset = job[1]\n",
    "\n",
    "    dirty_X_train = pd.read_csv(os.path.join(*job, \"dirty_X_train.csv\"))\n",
    "    dirty_y_train = pd.read_csv(os.path.join(*job, \"dirty_y_train.csv\"))\n",
    "    dirty_X_test = pd.read_csv(os.path.join(*job, \"dirty_X_test.csv\"))\n",
    "    dirty_y_test = pd.read_csv(os.path.join(*job, \"dirty_y_test.csv\"))\n",
    "    \n",
    "    dirty_X_train = dirty_X_train. rename(columns={'cost_living_index (US avg. = 100)':'cli'})\n",
    "    dirty_X_test = dirty_X_test. rename(columns={'cost_living_index (US avg. = 100)':'cli'})\n",
    "    dirty_X_train = dirty_X_train.fillna(0)\n",
    "    dirty_X_test = dirty_X_test.fillna(0)\n",
    "    X_train, y_train, X_test, y_test, mappings, mappings_dict = preprocess_data(dataset, \n",
    "                                                             dirty_X_train, dirty_y_train, \n",
    "                                                             [dirty_X_test], [dirty_y_test])\n",
    "    X_test = X_test[0]\n",
    "    y_test = y_test[0]\n",
    "    dirty_X_test = pd.read_csv(os.path.join(*job, \"dirty_X_test.csv\"))\n",
    "    null_data = dirty_X_test[dirty_X_test.isnull().any(axis=1)]\n",
    "    \n",
    "    null_data = null_data. rename(columns={'cost_living_index (US avg. = 100)':'cli'})\n",
    "   \n",
    "    \n",
    "    #print('here1')\n",
    "    #print(mappings_dict)\n",
    "    print(mappings_dict['cli']) # not found ...  \n",
    "    missing = [[]] * dirty_X_test.shape[0]\n",
    "    for i, row in null_data.iterrows():\n",
    "        \n",
    "        # append the original index of the missing feature\n",
    "        cols = null_data.columns.get_values()[np.where(pd.isnull(row))]\n",
    "\n",
    "        idx = [mappings_dict[col][0] for col in cols]\n",
    "        missing[i] = idx\n",
    "    missing = np.array(missing)\n",
    "\n",
    "    output = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    output['train']['nacl'] = (X_train, y_train)\n",
    "    output['test']['nacl'] = (X_test, y_test)\n",
    "    output['missing_test'] = missing\n",
    "    output['mappings1hot_dict'] = mappings_dict\n",
    "    output['mappings1hot_list'] = mappings\n",
    "    pickle.dump(dict(output), open(os.path.join(*job,\"data.p\"), 'wb'))\n",
    "\n",
    "    #print('here2')\n",
    "    max_acc = 0\n",
    "\n",
    "    for method in ['delete', 'impute_holoclean', 'impute_mean_mode', 'impute_mean_dummy', \n",
    "                   'impute_median_mode', 'impute_median_dummy', 'impute_mode_mode', 'impute_mode_dummy']:\n",
    "        #print('Titanic/v{}/missing_values/{}/logistic_regression/3659'.\\\n",
    "        #           format(split_seed, method))\n",
    "        split_seed = job[-1].split(\"_\")[1]\n",
    "        a =  results['{}/v{}/missing_values/{}/logistic_regression/3659'.\\\n",
    "                   format(dataset, split_seed, method)].copy()\n",
    "        #print(a)\n",
    "        del a['best_params']\n",
    "        del a['train_acc']\n",
    "        del a['val_acc']\n",
    "        max_key = max(a.items(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "        if a[max_key] > max_acc:\n",
    "            best_params_lr = results['{}/v{}/missing_values/{}/logistic_regression/3659'.\\\n",
    "                   format(dataset, split_seed, method)]['best_params']\n",
    "            max_acc = a[max_key]\n",
    "\n",
    "    clf = LogisticRegression(solver='lbfgs', \n",
    "    verbose=True, \n",
    "    C = best_params_lr['C'],\n",
    "    max_iter=2000, n_jobs=1).fit(X_train, y_train)\n",
    "    lr_pred = clf.predict(X_test)\n",
    "    lr_train_acc = accuracy(clf.predict(X_train), y_train)\n",
    "    lr_test_acc = accuracy(lr_pred, y_test)\n",
    "    lr_test_f1 = f1(lr_pred, y_test)\n",
    "\n",
    "    print(\"LR Train Accuracy: {} \\nLR Test  Accuracy: {}\".format(lr_train_acc, lr_test_acc))\n",
    "\n",
    "    W = np.hstack((clf.intercept_[:,None], clf.coef_))[0]\n",
    "    nacl = LR2NB_GP.LR2NB(W)\n",
    "    nacl.setObj(X_train, y_train)\n",
    "\n",
    "    # Using Mosek Solver\n",
    "    nacl.solve(verbose=1)\n",
    "\n",
    "    # Sanity Check to compare NaCL results with Logistic Regression\n",
    "    assert(1.0 == np.average( nacl.classify(X_test)  == clf.predict(X_test )))\n",
    "    assert(1.0 == np.average( nacl.classify(X_train) == clf.predict(X_train)))\n",
    "    nacl_pred = nacl.classify(X_test)\n",
    "    nacl_train_acc = accuracy(nacl.classify(X_train), y_train)\n",
    "    nacl_test_acc = accuracy(nacl_pred, y_test)\n",
    "    #print(nacl_pred)\n",
    "    #print(y_test)\n",
    "    nacl_test_f1 = f1(nacl_pred[0], y_test)\n",
    "\n",
    "    print(\"NaCL Train Accuracy: {} \\nNaCL Test  Accuracy: {}\".format(nacl_train_acc, nacl_test_acc))\n",
    "\n",
    "    NB = BernoulliNB().fit(X_train, y_train)\n",
    "    NB_pred = NB.predict(X_test)\n",
    "    nb_train_acc = accuracy(NB.predict(X_train), y_train)\n",
    "    nb_test_acc = accuracy(NB_pred, y_test)\n",
    "    nb_test_f1 = f1(NB_pred, y_test)\n",
    "\n",
    "    print(\"NB Train Accuracy: {} \\nNB Test  Accuracy: {}\".format(nb_train_acc, nb_test_acc))\n",
    "\n",
    "    # Make an example observations with some missing features\n",
    "\n",
    "    # setting the dimensions to be zero\n",
    "    missing_mask = np.zeros(X_test.shape) \n",
    "\n",
    "\n",
    "    miss = missing\n",
    "    for i in range(len(missing_mask)):\n",
    "        for j in range(len(miss[i])):\n",
    "            missing_mask[i][mappings[miss[i][j]]] = 1\n",
    "\n",
    "    a = nacl.predict_proba(X_test, missing = missing_mask)[:,1]\n",
    "    a = np.where(a > 0.5, 1, 0)\n",
    "\n",
    "    test_acc = accuracy(y_test, a)\n",
    "    test_f1 = f1(y_test, a)\n",
    "    print('nacl test acc with missing:', test_acc)\n",
    "    print('nacl test f1 with missing:', test_f1) # true, pred\n",
    "\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    result_dict[\"best_params\"] = best_params_lr\n",
    "\n",
    "\n",
    "    result_dict[\"{}_test_f1\".format('nacl_missing')] = test_f1\n",
    "    result_dict[\"{}_test_acc\".format('nacl_missing')] = test_acc\n",
    "\n",
    "    result_dict[\"{}_test_f1\".format('nacl')] = nacl_test_f1\n",
    "    result_dict[\"{}_test_acc\".format('nacl')] = nacl_test_acc\n",
    "    result_dict[\"{}_train_acc\".format('nacl')] = nacl_train_acc\n",
    "\n",
    "    result_dict[\"{}_test_f1\".format('nb')] = nb_test_f1\n",
    "    result_dict[\"{}_test_acc\".format('nb')] = nb_test_acc\n",
    "    result_dict[\"{}_train_acc\".format('nb')] = nb_train_acc\n",
    "\n",
    "    result_dict[\"{}_test_f1\".format('lr')] = lr_test_f1\n",
    "    result_dict[\"{}_test_acc\".format('lr')] = lr_test_acc\n",
    "    result_dict[\"{}_train_acc\".format('lr')] = lr_train_acc\n",
    "\n",
    "    print(result_dict)\n",
    "    save_result_mv(job, seed, result_dict, model_name, save_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nacl36",
   "language": "python",
   "name": "nacl36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
